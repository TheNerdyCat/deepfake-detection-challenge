{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from mtcnn==0.1.0) (4.1.2.30)\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from mtcnn==0.1.0) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from opencv-python>=4.1.0->mtcnn==0.1.0) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.13.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (5.1.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.1.0)\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import Model,Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = pd.read_json('../input/deepfake/metadata0.json')\n",
    "train1 = pd.read_json('../input/deepfake/metadata1.json')\n",
    "train2 = pd.read_json('../input/deepfake/metadata2.json')\n",
    "train3 = pd.read_json('../input/deepfake/metadata3.json')\n",
    "train4 = pd.read_json('../input/deepfake/metadata4.json')\n",
    "train5 = pd.read_json('../input/deepfake/metadata5.json')\n",
    "train6 = pd.read_json('../input/deepfake/metadata6.json')\n",
    "train7 = pd.read_json('../input/deepfake/metadata7.json')\n",
    "train8 = pd.read_json('../input/deepfake/metadata8.json')\n",
    "train9 = pd.read_json('../input/deepfake/metadata9.json')\n",
    "train10 = pd.read_json('../input/deepfake/metadata10.json')\n",
    "train11 = pd.read_json('../input/deepfake/metadata11.json')\n",
    "train12 = pd.read_json('../input/deepfake/metadata12.json')\n",
    "train13 = pd.read_json('../input/deepfake/metadata13.json')\n",
    "train14 = pd.read_json('../input/deepfake/metadata14.json')\n",
    "train15 = pd.read_json('../input/deepfake/metadata15.json')\n",
    "train16 = pd.read_json('../input/deepfake/metadata16.json')\n",
    "train17 = pd.read_json('../input/deepfake/metadata17.json')\n",
    "train18 = pd.read_json('../input/deepfake/metadata18.json')\n",
    "train19 = pd.read_json('../input/deepfake/metadata19.json')\n",
    "train20 = pd.read_json('../input/deepfake/metadata20.json')\n",
    "train21 = pd.read_json('../input/deepfake/metadata21.json')\n",
    "train22 = pd.read_json('../input/deepfake/metadata22.json')\n",
    "train23 = pd.read_json('../input/deepfake/metadata23.json')\n",
    "train24 = pd.read_json('../input/deepfake/metadata24.json')\n",
    "train25 = pd.read_json('../input/deepfake/metadata25.json')\n",
    "train26 = pd.read_json('../input/deepfake/metadata26.json')\n",
    "train27 = pd.read_json('../input/deepfake/metadata27.json')\n",
    "train28 = pd.read_json('../input/deepfake/metadata28.json')\n",
    "val1 = pd.read_json('../input/deepfake/metadata29.json')\n",
    "val2 = pd.read_json('../input/deepfake/metadata30.json')\n",
    "LABELS = ['REAL','FAKE']\n",
    "trains = [train0, train1, train2, train3, train4,\n",
    "          train5, train6, train7, train8, train9, train10,\n",
    "          train11, train12, train13, train14, train15,\n",
    "          train16, train17, train18, train19, train20, train21,\n",
    "          train22, train23, train24, train25, train26, train27,\n",
    "          train28]\n",
    "vals = [val1, val2]\n",
    "nums = list(range(len(trains)+1))\n",
    "val_nums = [29,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9c332837ae4195a23b9738870958dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1335e437067e47839af01641ae4fc802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_path(num, n):\n",
    "    num = str(num)\n",
    "    if len(num) == 2:\n",
    "        path = '../input/deepfake/DeepFake' + num + '/DeepFake' + num + '/' + x.replace('.mp4', '') + '.jpg'\n",
    "    else:\n",
    "        path='../input/deepfake/DeepFake0' + num + '/DeepFake0' + num + '/' + x.replace('.mp4', '') + '.jpg'\n",
    "    if not os.path.exists(path):\n",
    "       raise Exception\n",
    "    return path\n",
    "paths = []\n",
    "y = []\n",
    "for train,num in tqdm(zip(trains, nums), total=len(trains)):\n",
    "    images = list(train.columns.values)\n",
    "    for x in images:\n",
    "        try:\n",
    "            paths.append(get_path(num, x))\n",
    "            y.append(LABELS.index(train[x]['label']))\n",
    "        except Exception as err:\n",
    "            pass\n",
    "\n",
    "val_paths = []\n",
    "val_y = []\n",
    "for val,num in tqdm(zip(vals, val_nums), total=len(vals)):\n",
    "    images = list(val.columns.values)\n",
    "    for x in images:\n",
    "        try:\n",
    "            val_paths.append(get_path(num, x))\n",
    "            val_y.append(LABELS.index(val[x]['label']))\n",
    "        except Exception as err:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54474 fake train samples\n",
      "There are 9733 real train samples\n",
      "There are 3705 fake val samples\n",
      "There are 925 real val samples\n"
     ]
    }
   ],
   "source": [
    "print('There are '+ str(y.count(1)) + ' fake train samples')\n",
    "print('There are '+ str(y.count(0)) + ' real train samples')\n",
    "print('There are '+ str(val_y.count(1)) + ' fake val samples')\n",
    "print('There are '+ str(val_y.count(0)) + ' real val samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "real = []\n",
    "fake = []\n",
    "for m, n in zip(paths, y):\n",
    "    if n == 0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake = random.sample(fake, len(real))\n",
    "paths, y = [], []\n",
    "for x in real:\n",
    "    paths.append(x)\n",
    "    y.append(0)\n",
    "for x in fake:\n",
    "    paths.append(x)\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "fake = []\n",
    "for m, n in zip(val_paths, val_y):\n",
    "    if n == 0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake = random.sample(fake, len(real))\n",
    "val_paths,val_y = [],[]\n",
    "for x in real:\n",
    "    val_paths.append(x)\n",
    "    val_y.append(0)\n",
    "for x in fake:\n",
    "    val_paths.append(x)\n",
    "    val_y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9733 fake train samples\n",
      "There are 9733 real train samples\n",
      "There are 925 fake val samples\n",
      "There are 925 real val samples\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(y.count(1)) + ' fake train samples')\n",
    "print('There are ' + str(y.count(0)) + ' real train samples')\n",
    "print('There are ' + str(val_y.count(1)) + ' fake val samples')\n",
    "print('There are ' + str(val_y.count(0)) + ' real val samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d8f5e381534a188d64283d0daab37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19466), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66fb35651a34579925de972bc1d86b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def read_img(path):\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "X = []\n",
    "for img in tqdm(paths):\n",
    "    X.append(read_img(img))\n",
    "val_X = []\n",
    "for img in tqdm(val_paths):\n",
    "    val_X.append(read_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffle(X, y):\n",
    "    new_train = []\n",
    "    for m,n in zip(X, y):\n",
    "        new_train.append([m,n])\n",
    "    random.shuffle(new_train)\n",
    "    X,y = [],[]\n",
    "    for x in new_train:\n",
    "        X.append(x[0])\n",
    "        y.append(x[1])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "val_X, val_y = shuffle(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionLayer(a, b, c, d):\n",
    "    def func(x):\n",
    "        x1 = Conv2D(a, (1, 1), padding = 'same', activation = 'elu')(x)\n",
    "        \n",
    "        x2 = Conv2D(b, (1, 1), padding = 'same', activation = 'elu')(x)\n",
    "        x2 = Conv2D(b, (3, 3), padding = 'same', activation = 'elu')(x2)\n",
    "            \n",
    "        x3 = Conv2D(c, (1, 1), padding = 'same', activation = 'elu')(x)\n",
    "        x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding = 'same', activation = 'elu')(x3)\n",
    "        \n",
    "        x4 = Conv2D(d, (1, 1), padding='same', activation='elu')(x)\n",
    "        x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding = 'same', activation = 'elu')(x4)\n",
    "        y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
    "            \n",
    "        return y\n",
    "    return func\n",
    "    \n",
    "def define_model():\n",
    "    x = Input(shape = (256, 256, 3))\n",
    "    \n",
    "    x1 = InceptionLayer(1, 4, 4, 2)(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size = (2, 2), padding = 'same')(x1)\n",
    "    \n",
    "    x2 = InceptionLayer(2, 4, 4, 2)(x1)\n",
    "    x2 = BatchNormalization()(x2)        \n",
    "    x2 = MaxPooling2D(pool_size = (2, 2), padding = 'same')(x2)        \n",
    "        \n",
    "    x3 = Conv2D(16, (5, 5), padding = 'same', activation = 'elu')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D(pool_size = (2, 2), padding = 'same')(x3)\n",
    "        \n",
    "    x4 = Conv2D(16, (5, 5), padding = 'same', activation = 'elu')(x3)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = MaxPooling2D(pool_size = (4, 4), padding = 'same')(x4)\n",
    "        \n",
    "    y = Flatten()(x4)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(16)(y)\n",
    "    y = LeakyReLU(alpha = 0.1)(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(1, activation = 'sigmoid')(y)\n",
    "    model=Model(inputs = x, outputs = y)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr=1e-4))\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "lrs = [1e-3, 5e-4, 1e-4]\n",
    "def schedule(epoch):\n",
    "    return lrs[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 2)  8           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 1)  4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 4)  148         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 4)  148         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 2)  38          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 11) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 11) 44          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 11) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 4)  48          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 4)  48          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 2)  24          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 2)  24          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 4)  148         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 4)  148         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 2)  38          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 12) 0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 12) 48          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 12)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   4816        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 16)   6416        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 16)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           16400       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,725\n",
      "Trainable params: 28,615\n",
      "Non-trainable params: 110\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 72s 4ms/step - loss: 0.7134\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 66s 3ms/step - loss: 0.6354\n",
      "fold 0 model loss: 0.6613683886715287\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 63s 3ms/step - loss: 0.7284\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 61s 3ms/step - loss: 0.6409\n",
      "fold 1 model loss: 0.6566519505179226\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 61s 3ms/step - loss: 0.7171\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 59s 3ms/step - loss: 0.6407\n",
      "fold 2 model loss: 0.6599602011821195\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 63s 3ms/step - loss: 0.7252\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 61s 3ms/step - loss: 0.6407\n",
      "fold 3 model loss: 0.660801808346575\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 63s 3ms/step - loss: 0.7319\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 61s 3ms/step - loss: 0.6417\n",
      "fold 4 model loss: 0.6675817972079322\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import gc\n",
    "kfolds = 5\n",
    "models = []\n",
    "losses = []\n",
    "for i in range(kfolds):\n",
    "    model = define_model()\n",
    "    if i == 0:\n",
    "        model.summary()\n",
    "    model.load_weights('../input/meso-pretrain/MesoInception_DF')\n",
    "    model.fit([X], [y], epochs=2, callbacks = [LearningRateScheduler(schedule)])\n",
    "    models.append(model)\n",
    "    pred=model.predict([val_X])\n",
    "    loss=log_loss(val_y, pred)\n",
    "    losses.append(loss)\n",
    "    print('fold ' + str(i) + ' model loss: ' + str(loss))\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 4)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 2)  8           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 1)  4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 4)  148         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 4)  148         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 2)  38          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 11) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 11) 44          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 11) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 4)  48          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 4)  48          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 2)  24          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 2)  24          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 4)  148         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 4)  148         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 2)  38          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 12) 0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 12) 48          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 12)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 16)   4816        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 16)   6416        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 16)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           16400       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,725\n",
      "Trainable params: 28,615\n",
      "Non-trainable params: 110\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 61s 3ms/step - loss: 0.6860\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 59s 3ms/step - loss: 0.6300\n",
      "fold 0 model loss: 0.6870531581583861\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 63s 3ms/step - loss: 0.6919\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 62s 3ms/step - loss: 0.6361\n",
      "fold 1 model loss: 0.6535082849981012\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 61s 3ms/step - loss: 0.6870\n",
      "Epoch 2/2\n",
      "19466/19466 [==============================] - 59s 3ms/step - loss: 0.6292\n",
      "fold 2 model loss: 0.7009337538057888\n",
      "Epoch 1/2\n",
      "19466/19466 [==============================] - 65s 3ms/step - loss: 0.6920\n",
      "Epoch 2/2\n",
      "19232/19466 [============================>.] - ETA: 0s - loss: 0.6329"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import gc\n",
    "kfolds = 5\n",
    "for i in range(kfolds):\n",
    "    model = define_model()\n",
    "    if i == 0:\n",
    "        model.summary()\n",
    "    model.load_weights('../input/meso-pretrain/MesoInception_F2F')\n",
    "    model.fit([X], [y], epochs=2, callbacks = [LearningRateScheduler(schedule)])\n",
    "    models.append(model)\n",
    "    pred = model.predict([val_X])\n",
    "    loss = log_loss(val_y, pred)\n",
    "    losses.append(loss)\n",
    "    print('fold ' + str(i) + ' model loss: ' + str(loss))\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_pipline(X):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        pred = model.predict([X])\n",
    "        preds.append(pred)\n",
    "    return sum(preds) / len(preds)\n",
    "def larger_range(model_pred,time):\n",
    "    return (((model_pred - 0.5) * time) + 0.5).clip(0.35, 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = prediction_pipline(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some baselines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pred=np.random.random(len(val_X))\n",
    "print('random loss: ' + str(log_loss(val_y,random_pred.clip(0.45,0.65))))\n",
    "allone_pred=np.array([1 for _ in range(len(val_X))])\n",
    "print('1 loss: ' + str(log_loss(val_y,allone_pred)))\n",
    "allzero_pred=np.array([0 for _ in range(len(val_X))])\n",
    "print('0 loss: ' + str(log_loss(val_y,allzero_pred)))\n",
    "allpoint5_pred=np.array([0.5 for _ in range(len(val_X))])\n",
    "print('0.5 loss: ' + str(log_loss(val_y,allpoint5_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simple Averaging Loss: '+str(log_loss(val_y,model_pred.clip(0.35,0.65))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(larger_range(model_pred,2).mean())\n",
    "print(larger_range(model_pred,2).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answers(pred, real,num):\n",
    "    for i, (x, y) in enumerate(zip(pred, real)):\n",
    "        correct_incorrect = 'correct' if round(float(x), 0) == round(float(y), 0) else 'incorrect'\n",
    "        print(correct_incorrect + ' prediction: ' + str(x[0]) + ', answer: ' + str(y))\n",
    "        if i > num:\n",
    "            return\n",
    "def correct_precentile(pred, real):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for x, y in zip(pred, real):\n",
    "        if round(float(x), 0) == round(float(y), 0):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    print('number correct: ' + str(correct) + ', number incorrect: ' + str(incorrect))\n",
    "    print(str(round(correct / len(real) * 100, 1)) + '% correct' + ', ' + str(round(incorrect / len(real) * 100, 1)) + '% incorrect')\n",
    "check_answers(larger_range(model_pred, 2), val_y, 10)\n",
    "correct_precentile(larger_range(model_pred, 2), val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, val_X, val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SKIP = 10\n",
    "NUM_FRAME = 150\n",
    "test_dir = '/kaggle/input/deepfake-detection-challenge/test_videos/'\n",
    "filenames = os.listdir(test_dir)\n",
    "prediction_filenames = filenames\n",
    "test_video_files = [test_dir + x for x in filenames]\n",
    "detector = MTCNN()\n",
    "def detect_face(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    final = []\n",
    "    detected_faces_raw = detector.detect_faces(img)\n",
    "    if detected_faces_raw == []:\n",
    "        return []\n",
    "    confidences = []\n",
    "    for n in detected_faces_raw:\n",
    "        x, y, w, h = n['box']\n",
    "        final.append([x, y, w, h])\n",
    "        confidences.append(n['confidence'])\n",
    "    if max(confidences) < 0.7:\n",
    "        return []\n",
    "    max_conf_coord = final[confidences.index(max(confidences))]\n",
    "    return max_conf_coord\n",
    "def crop(img, x, y, w, h):\n",
    "    x -= 40\n",
    "    y -= 40\n",
    "    w += 80\n",
    "    h += 80\n",
    "    if x < 0:\n",
    "        x = 0\n",
    "    if y <= 0:\n",
    "        y = 0\n",
    "    return cv2.cvtColor(cv2.resize(img[y:y + h, x:x + w], (256, 256)), cv2.COLOR_BGR2RGB)\n",
    "def detect_video(video):\n",
    "    v_cap = cv2.VideoCapture(video)\n",
    "    v_cap.set(1, NUM_FRAME)\n",
    "    success, vframe = v_cap.read()\n",
    "    vframe = cv2.cvtColor(vframe, cv2.COLOR_BGR2RGB)\n",
    "    bounding_box = detect_face(vframe)\n",
    "    if bounding_box == []:\n",
    "        count = 0\n",
    "        current = NUM_FRAME\n",
    "        while bounding_box == [] and count < MAX_SKIP:\n",
    "            current += 1\n",
    "            v_cap.set(1, current)\n",
    "            success, vframe = v_cap.read()\n",
    "            vframe = cv2.cvtColor(vframe, cv2.COLOR_BGR2RGB)\n",
    "            bounding_box=detect_face(vframe)\n",
    "            count += 1\n",
    "        if bounding_box == []:\n",
    "            print('no faces found')\n",
    "            prediction_filenames.remove(video.replace('/kaggle/input/deepfake-detection-challenge/test_videos/',''))\n",
    "            return None\n",
    "    x,y,w,h=bounding_box\n",
    "    v_cap.release()\n",
    "    return crop(vframe,x,y,w,h)\n",
    "test_X = []\n",
    "for video in tqdm(test_video_files):\n",
    "    x = detect_video(video)\n",
    "    if x is None:\n",
    "        continue\n",
    "    test_X.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/deepfake-detection-challenge/sample_submission.csv')\n",
    "df_test['label'] = 0.5\n",
    "preds = prediction_pipline(test_X).clip(0.35, 0.65)\n",
    "for pred, name in zip(preds, prediction_filenames):\n",
    "    name = name.replace('/kaggle/input/deepfake-detection-challenge/test_videos/','')\n",
    "    df_test.iloc[list(df_test['filename']).index(name), 1] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.mean())\n",
    "print(preds.std())\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Work\n",
    "1. Do some more hyperparamater tuning\n",
    "2. Train on the whole video(and maybe also sound)\n",
    "3. Try LSTM-CNN\n",
    "4. K Folds(I will try it later when I upload more data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
