{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#!pip install ../input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True) # Enable GPU logging\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1,1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1,1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1,1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    # defining name basis\n",
    "    conv_name_base='res' + str(stage) + block + '_branch'\n",
    "    bn_name_base='bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides=(s,s), name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides=(s,s), name = conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes=2):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfolds = 5\n",
    "# Import the weights of our model\n",
    "models = []\n",
    "for i in range(kfolds):\n",
    "    model = ResNet50(input_shape=(64, 64, 3), classes=2)\n",
    "    model.load_weights('../output/resnet50_' + str(i) + '.h5')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64, 64, 3), classes=2)\n",
    "model.load_weights('../output/resnet50_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read video in.\n",
    "# Extract n frames\n",
    "# For each frame in video, detect all faces.\n",
    "# For each face detected - make REAL or FAKE prediction.\n",
    "# Take max/mean of predictions across faces in frame.\n",
    "# Take max/mean of all predictions across frames in video.\n",
    "# Edit submission script dataframe with name of video and final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos_path = '../input/test_videos/'\n",
    "test_videos_dir = os.listdir(test_videos_path)\n",
    "test_images_path = \"../input/test_images/\" # path to save test images to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos_files = [] # List of all train videos paths\n",
    "\n",
    "for file in test_videos_dir:\n",
    "    test_videos_files.append(test_videos_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(videos_dir_path, frames=1, conf_level=0.9):\n",
    "    \"\"\"\n",
    "    Inputs a directory of videos, extracts n frames. \n",
    "    Outputs images of ANY faces detected in those frames.\n",
    "    \n",
    "    NOTE: The is not the same function as in preprocessing.ipynb. It has been altered to suit the test environment.\n",
    "\n",
    "    videos_dir_path: (str) Path to your directory of videos\n",
    "    images_dir_path: (str) Path to where you'll save your images to\n",
    "    frames: (int or list) Number of frames. If int, take that many frames. If list, take frame numbers specified in list. \n",
    "    conf_level: (float) Confidence level for the face recognition model.\n",
    "    \"\"\"\n",
    "    def crop(img, x, y, w, h):\n",
    "        \"\"\"\n",
    "        Crop and reshape images to be uniform across all frames\n",
    "        \"\"\"\n",
    "        x -= 40\n",
    "        y -= 40\n",
    "        w += 80\n",
    "        h += 80\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y <= 0:\n",
    "            y = 0\n",
    "        return cv2.cvtColor(cv2.resize(img[y:y + h, x:x + w], (256, 256)), cv2.COLOR_BGR2RGB)\n",
    "    def read_image(img):\n",
    "        return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    def prepare_data(images):\n",
    "        m = len(images)\n",
    "        X = np.zeros((m, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "        for i, image_file in enumerate(images):\n",
    "            X[i,:] = read_image(image_file)\n",
    "        return X\n",
    "    submission_df = pd.DataFrame()\n",
    "    # Get video directory\n",
    "    if type(videos_dir_path) == list: \n",
    "        videos_dir = videos_dir_path # If it's a list of paths \n",
    "    else: \n",
    "        videos_dir = os.listdir(videos_dir_path) # List test vids\n",
    "        \n",
    "    for video in tqdm(range(0, 5)): #len(videos_dir)\n",
    "        \n",
    "        # Extract frames from video\n",
    "        file_name = videos_dir_path[video].split('/')[3]\n",
    "        file_path = videos_dir_path[video]\n",
    "        vid_name = file_name.split('.')[0]\n",
    "        frames_list = [] # We'll store the raw frames here\n",
    "        detector = MTCNN() # Facial recognition algorithm\n",
    "        if type(frames) == list:\n",
    "            for num in range(0, len(frames)):\n",
    "                cap = cv2.VideoCapture(file_path)\n",
    "                total_frames = cap.get(7)\n",
    "                vid_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                cap.set(1, num) # EDIT HERE FOR FRAME NUMBER\n",
    "                ret, frame = cap.read()\n",
    "                frames_list.append(frame)\n",
    "        else:\n",
    "            for num in range(0, frames):\n",
    "                cap = cv2.VideoCapture(file_path)\n",
    "                total_frames = cap.get(7)\n",
    "                vid_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                cap.set(1, random.randint(0, vid_length)) # EDIT HERE FOR FRAME NUMBER\n",
    "                ret, frame = cap.read()\n",
    "                frames_list.append(frame)\n",
    "        \n",
    "        # Extract faces from frames\n",
    "        \n",
    "        vid_preds = []\n",
    "        for i, image in enumerate(frames_list): \n",
    "            # Read image and detect faces\n",
    "            result = detector.detect_faces(image)\n",
    "            \n",
    "            # Extract and save faces as their own images\n",
    "            faces = []\n",
    "            for face in range(0, len(result)):\n",
    "                # Only extract the face if confidence is more than or equal to default 0.95\n",
    "                if result[face]['confidence'] >= conf_level:            \n",
    "                    startX, startY, endX, endY = result[face]['box'] # Get box coordinates\n",
    "                    crop_img = crop(frame, startX, startY, endX, endY)\n",
    "                    faces.append(crop_img)\n",
    "            \n",
    "            # Predict if face is FAKE or REAL\n",
    "            ROWS = 64\n",
    "            COLS = 64\n",
    "            CHANNELS = 3\n",
    "            CLASSES = 2\n",
    "            faces_prepared = prepare_data(faces)\n",
    "            faces_prepared =  faces_prepared / 255  ## DO WE NEED THIS??\n",
    "\n",
    "            frame_preds = []\n",
    "            for i, face in enumerate(faces_prepared):\n",
    "                face = np.expand_dims(face, axis=0)\n",
    "                face_pred = np.mean([model.predict(face) for model in models])\n",
    "                frame_preds.append(face_pred)\n",
    "\n",
    "            if len(frame_preds) > 0:\n",
    "                frame_pred = max(frame_preds) # Choose max pred across faces for overall frame pred\n",
    "                vid_preds.append(frame_pred)\n",
    "            else:\n",
    "                pass\n",
    "        vid_pred = np.mean(vid_preds) # Take mean pred across all frames for overall video pred\n",
    "        results_dict = dict(zip(['filename','label'], [file_name, vid_pred]))\n",
    "        submission_df = submission_df.append(results_dict, ignore_index=True)\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6d58259ed34adb892b814a7e130a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submission = make_submission(test_videos_files, frames=10)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
