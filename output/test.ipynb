{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ../input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos_path = '../input/test_videos/'\n",
    "test_videos_dir = os.listdir(test_videos_path)\n",
    "test_images_path = \"../input/test_images/\" # path to save test images to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos_files = [] # List of all train videos paths\n",
    "\n",
    "for file in test_videos_dir:\n",
    "    test_videos_files.append(test_videos_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(videos_dir_path, images_dir_path, frames=1, conf_level=0.95):\n",
    "    \"\"\"\n",
    "    Inputs a directory of videos, extracts n frames. \n",
    "    Outputs images of ANY faces detected in those frames.\n",
    "    \n",
    "    NOTE: The is not the same function as in preprocessing.ipynb. It has been altered to suit the test environment.\n",
    "\n",
    "    videos_dir_path: (str) Path to your directory of videos\n",
    "    images_dir_path: (str) Path to where you'll save your images to\n",
    "    frames: (int or list) Number of frames. If int, take that many frames. If list, take frame numbers specified in list. \n",
    "    conf_level: (float) Confidence level for the face recognition model.\n",
    "    \"\"\"\n",
    "    def crop(img, x, y, w, h):\n",
    "        \"\"\"\n",
    "        Crop and reshape images to be uniform across all frames\n",
    "        \"\"\"\n",
    "        x -= 40\n",
    "        y -= 40\n",
    "        w += 80\n",
    "        h += 80\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y <= 0:\n",
    "            y = 0\n",
    "        return cv2.cvtColor(cv2.resize(img[y:y + h, x:x + w], (256, 256)), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if type(videos_dir_path) == list: \n",
    "        videos_dir = videos_dir_path\n",
    "    else: \n",
    "        videos_dir = os.listdir(videos_dir_path) # List test vids\n",
    "    # Extract images from videos\n",
    "    if type(frames) == list:\n",
    "        print(f'Extracting frames {frames} from videos')\n",
    "    else:\n",
    "        print(f'Extracting {frames} random frame(s) from videos')\n",
    "        \n",
    "    frames_list = []\n",
    "    image_names = []\n",
    "    with tqdm(total=len(range(0, 10))) as pbar: #len(videos_dir)\n",
    "        for i in range(0, 10): #len(videos_dir)\n",
    "            #try:\n",
    "            if type(videos_dir_path) == list: \n",
    "                file_name = videos_dir_path[i].split('/')[3] # index 3 for test \n",
    "                file_path = videos_dir_path[i]\n",
    "                vid_name = file_name.split('.')[0]\n",
    "            else: \n",
    "                file_name = videos_dir[i] # file name with .ext\n",
    "                file_path = videos_dir_path + file_name # full file path\n",
    "                vid_name = file_name.split('.')[0] # file name without .ext\n",
    "            if type(frames) == list:\n",
    "                for num in range(0, len(frames)):\n",
    "                    cap = cv2.VideoCapture(file_path)\n",
    "                    total_frames = cap.get(7)\n",
    "                    vid_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    cap.set(1, num) # EDIT HERE FOR FRAME NUMBER\n",
    "                    ret, frame = cap.read()\n",
    "                    frames_list.append(frame)\n",
    "                    image_name = vid_name + '_' + str(num) + '.jpg'\n",
    "                    image_names.append(image_name)\n",
    "            else:\n",
    "                for num in range(0, frames):\n",
    "                    cap = cv2.VideoCapture(file_path)\n",
    "                    total_frames = cap.get(7)\n",
    "                    vid_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    cap.set(1, random.randint(0, vid_length)) # EDIT HERE FOR FRAME NUMBER\n",
    "                    ret, frame = cap.read()\n",
    "                    frames_list.append(frame)\n",
    "                    image_name = vid_name + '_' + str(num) + '.jpg'\n",
    "                    image_names.append(image_name)\n",
    "            pbar.update(1)\n",
    "            #except:\n",
    "            #    pass\n",
    "    detector = MTCNN()\n",
    "\n",
    "    print('Extracting faces from frames')\n",
    "    faces = []\n",
    "    with tqdm(total=len(frames_list)) as pbar:\n",
    "        \n",
    "        for image in range(0, len(frames_list)):\n",
    "            try:\n",
    "                image_name = image_names[image] # Get image name without .ext\n",
    "                # Read image and detect faces\n",
    "                frame = frames_list[image]\n",
    "                result = detector.detect_faces(frame)\n",
    "                \n",
    "                # Extract and save faces as their own images\n",
    "                for face in range(0, len(result)):\n",
    "                    # Only extract the face if confidence is more than or equal to default 0.95\n",
    "                    if result[face]['confidence'] >= conf_level:            \n",
    "                        startX, startY, endX, endY = result[face]['box'] # Get box coordinates\n",
    "                        crop_img = crop(frame, startX, startY, endX, endY)\n",
    "                        faces.append(crop_img)\n",
    "            except:\n",
    "                pass\n",
    "            pbar.update(1)\n",
    "        return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 1 random frame(s) from videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b196f87ece4d5695710ccf62a7bf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting faces from frames\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8898059ceb774e579919bb7350c89c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "faces = extract_faces(test_videos_files, test_images_path, frames=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True) # Enable GPU logging\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1,1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1,1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1,1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    # defining name basis\n",
    "    conv_name_base='res' + str(stage) + block + '_branch'\n",
    "    bn_name_base='bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides=(s,s), name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides=(s,s), name = conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes=2):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64, 64, 3), classes=2)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('../output/resnet50_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 3\n",
    "CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img):\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def prepare_data(images):\n",
    "    m = len(images)\n",
    "    X = np.zeros((m, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(images):\n",
    "        X[i,:] = read_image(image_file)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_x = prepare_data(faces)\n",
    "X_test = test_set_x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
