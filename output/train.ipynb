{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Following from [Preprocessing](https://github.com/TheNerdyCat/deepfake-detection-challenge/blob/master/output/preprocessing.ipynb), this stage will look at data augmentation and subsequently training the model.\n",
    "\n",
    "First we will undersample the images to balance REAL and FAKE images in both the train and validation sets. There are actually more FAKE images than REAL in this dataset, so this will be addressed accordingly.\n",
    "\n",
    "We will read our extracted faces using OpenCV and perform any data augmentation. Following this, we will define X and X_val. Then we'll read the metadata to label the extracted faces as FAKE or REAL, defining them into y and y_val.\n",
    "\n",
    "After we have our training data and validation data ready and shuffled, we'll train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json # To read the metadata\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "#import torch\n",
    "#import keras\n",
    "#from keras import Model, Sequential\n",
    "#from keras.layers import *\n",
    "#from keras.optimizers import *\n",
    "#from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True) # Enable GPU logging\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = '../input/train_images/'\n",
    "train_images = os.listdir(train_images_path)\n",
    "metadata_path = '../input/train_metadata/'\n",
    "metadata_dir = os.listdir(metadata_path)\n",
    "\n",
    "# Read in all the metadata files to make one inclusive dict\n",
    "metadata = {}\n",
    "for i, file in enumerate(metadata_dir):\n",
    "    with open('../input/train_metadata/' + file) as json_file:\n",
    "        metadata = {**metadata, **json.load(json_file)}\n",
    "\n",
    "X_paths = []\n",
    "for img in train_images:\n",
    "    img = train_images_path + img\n",
    "    X_paths.append(img)\n",
    "\n",
    "y = []\n",
    "for label in train_images:\n",
    "    if metadata[label.split('_')[0] + '.mp4']['label'] == 'REAL':\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    new_train = []\n",
    "    for m, n in zip(X, y):\n",
    "        new_train.append([m, n])\n",
    "    random.shuffle(new_train)\n",
    "    X, y = [], []\n",
    "    for x in new_train:\n",
    "        X.append(x[0])\n",
    "        y.append(x[1])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paths, y = shuffle(X_paths, y)\n",
    "\n",
    "# Create X_val from 10% of X\n",
    "X_val_paths = X_paths[:round(len(X_paths) / 100 * 25)]\n",
    "X_paths = X_paths[round(len(X_paths) / 100 * 25):]\n",
    "\n",
    "# Create y_val from 10% of y\n",
    "y_val = y[:round(len(y) / 100 * 25)]\n",
    "y = y[round(len(y) / 100 * 25):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paths, y = shuffle(X_paths, y)\n",
    "X_val_paths, y_val = shuffle(X_val_paths, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2332 fake train samples\n",
      "There are 463 real train samples\n",
      "There are 783 fake val samples\n",
      "There are 149 real val samples\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(y.count(1)) + ' fake train samples')\n",
    "print('There are ' + str(y.count(0)) + ' real train samples')\n",
    "print('There are ' + str(y_val.count(1)) + ' fake val samples')\n",
    "print('There are ' + str(y_val.count(0)) + ' real val samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n",
    "Next we'll balance our data, using undersampling techniques. Source for this method can be found [here](https://www.kaggle.com/unkownhihi/starter-kernel-with-cnn-model-ll-lb-0-69235#Apply-Underbalancing-Techinique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "fake = []\n",
    "for m, n in zip(X_paths, y):\n",
    "    if n == 0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake = random.sample(fake, len(real))\n",
    "X_paths, y = [], []\n",
    "for x in real:\n",
    "    X_paths.append(x)\n",
    "    y.append(0)\n",
    "for x in fake:\n",
    "    X_paths.append(x)\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "fake = []\n",
    "for m, n in zip(X_val_paths, y_val):\n",
    "    if n == 0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake = random.sample(fake, len(real))\n",
    "X_val_paths, y_val = [], []\n",
    "for x in real:\n",
    "    X_val_paths.append(x)\n",
    "    y_val.append(0)\n",
    "for x in fake:\n",
    "    X_val_paths.append(x)\n",
    "    y_val.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 463 fake train samples\n",
      "There are 463 real train samples\n",
      "There are 149 fake val samples\n",
      "There are 149 real val samples\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(y.count(1)) + ' fake train samples')\n",
    "print('There are ' + str(y.count(0)) + ' real train samples')\n",
    "print('There are ' + str(y_val.count(1)) + ' fake val samples')\n",
    "print('There are ' + str(y_val.count(0)) + ' real val samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation will go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 3\n",
    "CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def prepare_data(images):\n",
    "    m = len(images)\n",
    "    X = np.zeros((m, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "    y = np.zeros((1, m), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(images):\n",
    "        X[i,:] = read_image(image_file)\n",
    "        # \n",
    "        if metadata[image_file.split('/')[3].split('_')[0]+'.mp4'] == 'REAL':\n",
    "            y[0, i] = 1\n",
    "        elif metadata[image_file.split('/')[3].split('_')[0]+'.mp4'] == 'FAKE':\n",
    "            y[0, i] = 0\n",
    "    return X, y\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y = prepare_data(X_paths)\n",
    "val_set_x, val_set_y = prepare_data(X_val_paths)\n",
    "\n",
    "X_train = train_set_x / 255\n",
    "X_val = val_set_x / 255\n",
    "\n",
    "Y_train = convert_to_one_hot(train_set_y, CLASSES).T\n",
    "Y_val = convert_to_one_hot(val_set_y, CLASSES).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 926\n",
      "Number of val examples = 298\n",
      "X_train shape: (926, 64, 64, 3)\n",
      "Y_train shape: (926, 2)\n",
      "X_val shape: (298, 64, 64, 3)\n",
      "Y_val shape: (298, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples =\", X_train.shape[0])\n",
    "print (\"Number of val examples =\", X_val.shape[0])\n",
    "print (\"X_train shape:\", X_train.shape)\n",
    "print (\"Y_train shape:\", Y_train.shape)\n",
    "print (\"X_val shape:\", X_val.shape)\n",
    "print (\"Y_val shape:\", Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "We implement our ResNet using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1,1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1,1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1,1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    # defining name basis\n",
    "    conv_name_base='res' + str(stage) + block + '_branch'\n",
    "    bn_name_base='bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides=(s,s), name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides=(s,s), name = conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes=2):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "Fold : 0\n",
      "########################\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 20s 21ms/sample - loss: 0.1550 - accuracy: 0.9687\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 2s 2ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 3s 3ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 6s 7ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "Epoch 1/100\n",
      "926/926 [==============================] - 8s 8ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "926/926 [==============================] - 1s 831us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "926/926 [==============================] - 1s 825us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "926/926 [==============================] - 1s 831us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "926/926 [==============================] - 1s 830us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "926/926 [==============================] - 1s 912us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Fold 0 log loss: 0.0\n",
      "\n",
      "########################\n",
      "Fold : 1\n",
      "########################\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 13s 14ms/sample - loss: 0.2233 - accuracy: 0.9676\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "Epoch 1/100\n",
      "926/926 [==============================] - 2s 2ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "926/926 [==============================] - 1s 843us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "926/926 [==============================] - 1s 833us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "926/926 [==============================] - 1s 829us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "926/926 [==============================] - 1s 833us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "926/926 [==============================] - 1s 920us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Fold 0 log loss: 8.142637767033016e-07\n",
      "\n",
      "########################\n",
      "Fold : 2\n",
      "########################\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 12s 13ms/sample - loss: 0.2088 - accuracy: 0.9622\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "Epoch 1/100\n",
      "926/926 [==============================] - 2s 2ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "926/926 [==============================] - 1s 843us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "926/926 [==============================] - 1s 847us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "926/926 [==============================] - 1s 852us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "926/926 [==============================] - 1s 842us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "926/926 [==============================] - 1s 931us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Fold 0 log loss: 0.0\n",
      "\n",
      "########################\n",
      "Fold : 3\n",
      "########################\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 13s 14ms/sample - loss: 0.2196 - accuracy: 0.9687\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "Epoch 1/100\n",
      "926/926 [==============================] - 2s 2ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "926/926 [==============================] - 1s 848us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "926/926 [==============================] - 1s 841us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "926/926 [==============================] - 1s 838us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "926/926 [==============================] - 1s 838us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "926/926 [==============================] - 1s 941us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Fold 0 log loss: 2.3841860752327193e-07\n",
      "\n",
      "########################\n",
      "Fold : 4\n",
      "########################\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 12s 13ms/sample - loss: 0.3066 - accuracy: 0.9654\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "926/926 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Train on 926 samples\n",
      "Epoch 1/100\n",
      "926/926 [==============================] - 2s 2ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "926/926 [==============================] - 1s 860us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "926/926 [==============================] - 1s 856us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "926/926 [==============================] - 1s 843us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "926/926 [==============================] - 1s 847us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "926/926 [==============================] - 1s 941us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "Fold 0 log loss: 3.715096414794824e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "losses = []\n",
    "for fold in range(k_folds):\n",
    "    print('########################')\n",
    "    print(f'Fold : {fold}')\n",
    "    print('########################')\n",
    "\n",
    "    model = ResNet50(input_shape=(64, 64, 3), classes=2)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='loss', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=2, \n",
    "                   patience=5)\n",
    "    for i in range(1):\n",
    "        model.fit(X_train, Y_train, verbose=1)\n",
    "    for i in range(1):\n",
    "        model.fit(X_train, Y_train, batch_size=64, verbose=1)\n",
    "    for i in range(1):\n",
    "        model.fit(X_train, Y_train, batch_size=128, verbose=1)\n",
    "    for i in range(1):\n",
    "        model.fit(X_train, Y_train, batch_size=256, verbose=1)\n",
    "        \n",
    "    model.fit(X_train, Y_train, callbacks=[es], epochs=100, batch_size=1024, verbose=1)\n",
    "    \n",
    "    pred = model.predict([X_val])\n",
    "    loss = log_loss(Y_val, pred)\n",
    "    model.save_weights(f'resnet50_{i}.h5')\n",
    "    print('')\n",
    "    print('Fold ' + str(fold) + ' log loss: ' + str(loss))\n",
    "    print('')\n",
    "    losses.append(loss)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_val)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL 1 - IGNORE FOR NOW ##\n",
    "\n",
    "#def InceptionLayer(a, b, c, d):\n",
    "#    def func(x):\n",
    "#        x1 = Conv2D(a, (1, 1), padding='same', activation='elu')(x)\n",
    "#        \n",
    "#        x2 = Conv2D(b, (1, 1), padding='same', activation='elu')(x)\n",
    "#        x2 = Conv2D(b, (3, 3), padding='same', activation='elu')(x2)\n",
    "#            \n",
    "#        x3 = Conv2D(c, (1, 1), padding='same', activation='elu')(x)\n",
    "#        x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides=1, padding='same', activation='elu')(x3)\n",
    "#        \n",
    "#        x4 = Conv2D(d, (1, 1), padding='same', activation='elu')(x)\n",
    "#        x4 = Conv2D(d, (3, 3), dilation_rate=3, strides=1, padding='same', activation='elu')(x4)\n",
    "#        y = Concatenate(axis=-1)([x1, x2, x3, x4])\n",
    "#            \n",
    "#        return y\n",
    "#    return func\n",
    "#    \n",
    "#def define_model(shape=(256, 256, 3)):\n",
    "#    x = Input(shape=shape)\n",
    "#    \n",
    "#    x1 = InceptionLayer(1, 4, 4, 2)(x)\n",
    "#    x1 = BatchNormalization()(x1)\n",
    "#    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "#    \n",
    "#    x2 = InceptionLayer(2, 4, 4, 2)(x1)\n",
    "#    x2 = BatchNormalization()(x2)        \n",
    "#    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
    "#        \n",
    "#    x3 = Conv2D(16, (5, 5), padding='same', activation='elu')(x2)\n",
    "#    x3 = BatchNormalization()(x3)\n",
    "#    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "#        \n",
    "#    x4 = Conv2D(16, (5, 5), padding='same', activation='elu')(x3)\n",
    "#    x4 = BatchNormalization()(x4)\n",
    "#    x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "#    \n",
    "#    y = Flatten()(x4)\n",
    "#    y = Dropout(0.5)(y)\n",
    "#    y = Dense(16)(y)\n",
    "#    y = LeakyReLU(alpha=0.1)(y)\n",
    "#    y = Dropout(0.5)(y)\n",
    "#    y = Dense(1, activation='sigmoid')(y)\n",
    "#    model = Model(inputs=x, outputs=y)\n",
    "#    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4))\n",
    "#    return model\n",
    "#\n",
    "#df_model = define_model()\n",
    "#lrs = [1e-3, 5e-4, 1e-4]\n",
    "#def schedule(epoch):\n",
    "#    return lrs[epoch]\n",
    "#kfolds = 5\n",
    "#losses = []\n",
    "#\n",
    "#models = []\n",
    "#i = 0\n",
    "#while len(models) < kfolds:\n",
    "#    model = define_model()\n",
    "#    model.fit([X], [y], epochs=2, callbacks=[LearningRateScheduler(schedule)])\n",
    "#    pred = model.predict([X_val])\n",
    "#    loss = log_loss(y_val, pred)\n",
    "#    losses.append(loss)\n",
    "#    print('Fold ' + str(i) + ' model loss: ' + str(loss))\n",
    "#    print('')\n",
    "#    if loss < 0.68:\n",
    "#        models.append(model)\n",
    "#        i += 1\n",
    "#    else:\n",
    "#        print('')\n",
    "#        print('RETRAINING')\n",
    "#        print('############################')\n",
    "#    K.clear_session()\n",
    "#    #del model\n",
    "#    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
