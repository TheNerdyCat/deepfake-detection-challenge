{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ../input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.patches import Rectangle # For drawing rectangle around faces\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "#import keras\n",
    "#from keras import Model, Sequential\n",
    "#from keras.layers import *\n",
    "#from keras.optimizers import *\n",
    "#from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import torch\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import log_loss\n",
    "\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import json # To read the metadata\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define our directory paths and directory lists - including the directory where we will save our train and test images that we extract from the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos_path = '../input/train_videos/'\n",
    "test_videos_path = '../input/test_videos/'\n",
    "train_metadata_path = '../input/train_metadata/'\n",
    "test_metadata_path = '../input/test_metadata/'\n",
    "train_images_path = \"../input/train_images/\" # path to save train images to\n",
    "test_images_path = \"../input/test_images/\" # path to save test images to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll loop through all of the videos in all the train folder locations to make one list of paths. We will also rename the metadata (to determine which folder it corresponds to) and copy it to a new directory 'train_metadata'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos_files = [] # List of all train videos paths\n",
    "train_metadata_files = [] # List of train metadata paths\n",
    "\n",
    "for folder in enumerate(os.listdir(train_videos_path)):\n",
    "    for file in os.listdir(train_videos_path + folder[1]):\n",
    "        if file == 'metadata.json':\n",
    "            # Rename and copy the metadata to a new directory\n",
    "            old_path = train_videos_path + folder[1] + '/' + file\n",
    "            new_path = train_metadata_path + 'metadata' + str(folder[0]) + '.json'\n",
    "            shutil.copy(old_path, new_path)            \n",
    "            train_metadata_files.append(new_path)\n",
    "        else:\n",
    "            train_videos_files.append(train_videos_path + folder[1] + '/'+ file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop round all the videos in our directory to extract images for each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(videos_dir_path, images_dir_path, frames=1, conf_level=0.95):\n",
    "    \"\"\"\n",
    "    Inputs a directory of videos, extracts n frames. \n",
    "    Outputs images of ANY faces detected in those frames.\n",
    "    \n",
    "    videos_dir_path: (str) Path to your directory of videos\n",
    "    images_dir_path: (str) Path to where you'll save your images to\n",
    "    frames: (int or list) Number of frames. If int, take that many \n",
    "            frames. If list, take frame numbers specified in list. \n",
    "    \"\"\"\n",
    "    def crop(img, x, y, w, h):\n",
    "        \"\"\"\n",
    "        Crop and reshape images to be uniform across all frames\n",
    "        \"\"\"\n",
    "        x -= 40\n",
    "        y -= 40\n",
    "        w += 80\n",
    "        h += 80\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y <= 0:\n",
    "            y = 0\n",
    "        return cv2.cvtColor(cv2.resize(img[y:y + h, x:x + w], (256, 256)), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    device = 'CUDA:0' if torch.cuda.is_available() else 'CPU'\n",
    "    print(f'Running on device: {device}')\n",
    "    if type(videos_dir_path) == list: \n",
    "        videos_dir = videos_dir_path\n",
    "    else: \n",
    "        videos_dir = os.listdir(videos_dir_path) # List train vids\n",
    "    \n",
    "    # Extract images from videos\n",
    "    if type(frames) == list:\n",
    "        print(f'Extracting frames {frames} from videos')\n",
    "    else:\n",
    "        print(f'Extracting {frames} random frames from videos')\n",
    "        \n",
    "    with tqdm(total=len(range(0, len(videos_dir)))) as pbar: \n",
    "        for i in range(0, len(videos_dir)): \n",
    "            try:\n",
    "                if type(videos_dir_path) == list: \n",
    "                    file_name = videos_dir_path[i].split('/')[4]\n",
    "                    file_path = videos_dir_path[i]\n",
    "                    vid_name = file_name.split('.')[0]\n",
    "                else: \n",
    "                    file_name = videos_dir[i] # file name with .ext\n",
    "                    file_path = videos_dir_path + file_name # full file path\n",
    "                    vid_name = file_name.split('.')[0] # file name without .ext\n",
    "\n",
    "                if type(frames) == list:\n",
    "                    for num in range(0, len(frames)):\n",
    "                        cap = cv2.VideoCapture(file_path)\n",
    "                        total_frames = cap.get(7)\n",
    "                        vid_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                        cap.set(1, num) # EDIT HERE FOR FRAME NUMBER\n",
    "                        ret, frame = cap.read()\n",
    "                        image_name = vid_name + '_' + str(num) + '.jpg'\n",
    "                        cv2.imwrite(os.path.join(train_images_path, image_name), frame) # Save frame as image\n",
    "                        cv2.destroyAllWindows()\n",
    "                        cap.release()\n",
    "                else:\n",
    "                    for num in range(0, frames):\n",
    "                        cap = cv2.VideoCapture(file_path)\n",
    "                        total_frames = cap.get(7)\n",
    "                        vid_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                        cap.set(1, random.randint(0, vid_length)) # EDIT HERE FOR FRAME NUMBER\n",
    "                        ret, frame = cap.read()\n",
    "                        image_name = vid_name + '_' + str(num) + '.jpg'\n",
    "                        cv2.imwrite(os.path.join(train_images_path, image_name), frame) # Save frame as image\n",
    "                        cv2.destroyAllWindows()\n",
    "                        cap.release()\n",
    "                pbar.update(1)\n",
    "            except:\n",
    "                pass\n",
    "    images_dir = os.listdir(images_dir_path) # List newly created training images\n",
    "    detector = MTCNN()\n",
    "\n",
    "    print('Extracting faces from frames')\n",
    "    with tqdm(total=len(images_dir)) as pbar:\n",
    "        try:\n",
    "            for image in range(0, len(images_dir)):\n",
    "                image_name = images_dir[image].split('.')[0] # Get image name without .ext\n",
    "\n",
    "                # Read image and detect faces\n",
    "                frame = cv2.imread(images_dir_path + images_dir[image])\n",
    "                result = detector.detect_faces(frame)\n",
    "\n",
    "                # Extract and save faces as their own images\n",
    "                for face in range(0, len(result)):\n",
    "                    # Only extract the face if confidence is more than or equal to default 0.95\n",
    "                    if result[face]['confidence'] >= conf_level:            \n",
    "                        startX, startY, endX, endY = result[face]['box'] # Get box coordinates\n",
    "                        crop_img = crop(frame, startX, startY, endX, endY)\n",
    "                        cv2.imwrite(images_dir_path + image_name + '_' + str(face) + '.jpg', crop_img)\n",
    "                os.remove(images_dir_path + images_dir[image]) # Delete original image7\n",
    "        except:\n",
    "            pass\n",
    "            print()\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CPU\n",
      "Extracting 1 random frames from videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c449135f6784ed6bac08f7a32410bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119146.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting faces from frames\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d8136ac9154fa597cf2787e7548876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=118105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_faces(train_videos_files, train_images_path, frames=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completed the face extraction and image preprocessing stage. We should now have a directory of images that we will train our model with. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
